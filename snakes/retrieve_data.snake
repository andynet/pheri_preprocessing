rule download:
  output:
    '{data_dir}/001_{database}.genomes.fasta',
    '{data_dir}/001_{database}.genomes.conversion'
  params:
    script_dir=SCRIPT_DIR
  log:
    '{data_dir}/001_{database}.stdout',
    '{data_dir}/001_{database}.stderr'
  shell:
    '''
    mkdir -p {wildcards.data_dir}
    {params.script_dir}/001_download_from_{wildcards.database}.py {wildcards.data_dir} > {log[0]} 2> {log[1]}
    '''

rule merge:
  input:
    expand(['{{data_dir}}/001_{database}.genomes.fasta', '{{data_dir}}/001_{database}.genomes.conversion'],
            database=DATABASES,
            ),
  output:
    '{data_dir}/002_merged.genomes.conversion',
    '{data_dir}/002_merged.genomes.fasta'
  shell:
    '''
    cat {wildcards.data_dir}/001_*.genomes.conversion > {output[0]}
    cat {wildcards.data_dir}/001_*.genomes.fasta      > {output[1]}
    '''

rule eliminate_duplicates:
  input:
    '{data_dir}/002_merged.genomes.conversion',
    '{data_dir}/002_merged.genomes.fasta'
  output:
    '{data_dir}/003_deduplicated.genomes.conversion',
    '{data_dir}/003_deduplicated.genomes.fasta'
  params:
    script_dir=SCRIPT_DIR
  shell:
    '''
    {params.script_dir}/003_deduplicate_genomes.py {input[1]} {input[0]} {wildcards.data_dir}
    '''

rule count_hosts:
  input:
    '{data_dir}/003_deduplicated.genomes.conversion'
  output:
    '{data_dir}/004_hosts.tsv',
    '{data_dir}/004_genera.tsv',
    '{data_dir}/004_genera.counts',
    '{data_dir}/004_genera_of_interest'
  params:
    script_dir=SCRIPT_DIR,

  shell:
    '''
    {params.script_dir}/004_get_hosts.py -i {input[0]}                                   \
                                         -o {output[0]}                                  \
                                         -d {params.script_dir}/004_taxonomies.json

    less {output[0]} | cut -f1,2 | sort | uniq > {output[1]}
    less {output[1]} | cut -f2 | sort | uniq -c | sort -nr > {output[2]}
    less {output[2]} | grep -v "None" | head -n 50 | tr -s " " | cut -f3 -d " " > {output[3]}
    '''
